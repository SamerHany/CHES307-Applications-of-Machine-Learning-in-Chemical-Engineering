{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Properties of Wound Sealing Powder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this assignment, we will explore the application of Machine Learning in Pharmaceutical Research and Development (R&D) to predict the properties of a final product, specifically a wound sealing powder used in surgeries. \n",
    "\n",
    "The production process involves a batch reactor where the ingredients are mixed, heated, and then cooled. The ingredients remain constant as they are based on a specific formula. All experiments are done in room temperature (35°C).\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand data exploration, cleaning, and preprocessing\n",
    "- Learn to identify and handle logical errors in process data\n",
    "- Practice feature selection with domain knowledge\n",
    "- Develop and optimize machine learning models\n",
    "- Learn to use model predictions for process optimization\n",
    "\n",
    "## Data Description\n",
    "\n",
    "- **Sample_Number**\n",
    "- **Heating_Temperature_C:** Heating temperature during the process (in degrees Celsius).\n",
    "- **Heating_Duration_min:** Duration for which the mixture is heated (in minutes).\n",
    "- **Heating_Rate_per_min:** Rate at which the heat is transferred to the fluid (in Kj/min).\n",
    "- **Cooling_Temperature_C:** Final cooling temperature after the process (in degrees Celsius).\n",
    "- **Heat_Rejection_Rate_per_min:** Rate at which the heat is rejected during cooling (in Kj/min).\n",
    "- **Final_Product_Absorption_Capacity:** Measured Absorption capacity of the final wound sealing powder (in ml/g). This is the target variable.\n",
    "- **Start_Timestamp:** Experiment starting time.\n",
    "- **End_Timestamp:** Experiment end time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration\n",
    "\n",
    "### Task 1.1: Load and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('wound_sealing_trial_data.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"\\nDataset Info:\")\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(df):\n",
    "    \"\"\"Plot histograms for all numerical features\"\"\"\n",
    "    # Remove unnecessary features\n",
    "    \n",
    "    num_features = len(df.columns)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(df.columns):\n",
    "        if idx < len(axes):\n",
    "            sns.histplot(data=df, x=col, ax=axes[idx])\n",
    "            axes[idx].set_title(f'Distribution of {col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"Plot correlation matrix heatmap\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_relationships(df, target='Final_Product_Absorption_Capacity'):\n",
    "    \"\"\"Plot relationships between features and target\"\"\"\n",
    "\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    n_features = len(features)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 20))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, feature in enumerate(features):\n",
    "        if idx < len(axes):\n",
    "            sns.scatterplot(data=df, x=feature, y=target, ax=axes[idx])\n",
    "            axes[idx].set_title(f'{feature} vs {target}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare df for data visualization by dropping irrelevant features\n",
    "# TODO\n",
    "df\n",
    "\n",
    "plot_feature_distributions(df)\n",
    "plot_correlation_matrix(df)\n",
    "plot_feature_relationships(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Logical Error Handling\n",
    "\n",
    "### Task 2.1: Identify and Handle Logical Errors\n",
    "\n",
    "Develop two functions, one to identify logical errors, and another one to fix them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_logical_errors(df):\n",
    "    \"\"\"Check for logical errors in the data\"\"\"\n",
    "    errors = {\n",
    "        'cooling_temp_higher': df['Cooling_Temperature_C'] > df['Heating_Temperature_C'],\n",
    "        # TODO\n",
    "    }\n",
    "    \n",
    "    print(\"Logical Errors Found:\")\n",
    "    for error_type, mask in errors.items():\n",
    "        print(f\"{error_type}: {mask.sum()} instances\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def fix_logical_errors(df):\n",
    "    \"\"\"Fix logical errors in the data\"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Check for logical errors\n",
    "errors = check_logical_errors(df)\n",
    "\n",
    "# Fix logical errors\n",
    "df_clean = fix_logical_errors(df)\n",
    "\n",
    "# Verify fixes\n",
    "print(\"\\nAfter fixing logical errors:\")\n",
    "check_logical_errors(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Handle Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"Handle missing values in the dataset\"\"\"\n",
    "    print(\"Missing values before handling:\")\n",
    "    display(df.isnull().sum())\n",
    "\n",
    "    # Implement logic for handling missing values\n",
    "    # You can include multiple methods depending on each feature/case\n",
    "    # TODO\n",
    "\n",
    "    \n",
    "    print(\"\\nMissing values after handling:\")\n",
    "    display(df_clean.isnull().sum())\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# Handle missing values\n",
    "df_clean = handle_missing_values(df_clean)\n",
    "\n",
    "# Display summary of cleaned data\n",
    "print(\"\\nSummary of cleaned data:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Feature Selection and Engineering\n",
    "\n",
    "### Task 3.1: Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(X, y):\n",
    "    \"\"\"Analyze feature importance using multiple methods\"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_clean.drop(['Final_Product_Absorption_Capacity'], axis=1)\n",
    "y = df_clean['Final_Product_Absorption_Capacity']\n",
    "\n",
    "# Analyze feature importance\n",
    "importance_df = analyze_feature_importance(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Feature Engineering (Optional)\n",
    "\n",
    "Create engineered features as needed. After creating engineered features, fun the feature importance function you developed earlier to evaluate their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(X):\n",
    "    \"\"\"Create engineered features\"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    return X_engineered\n",
    "\n",
    "# Engineer features\n",
    "X_engineered = engineer_features(X)\n",
    "\n",
    "# Analyze importance of engineered features\n",
    "importance_df_engineered = analyze_feature_importance(X_engineered, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Feature Selection\n",
    "\n",
    "Select the relevant features that you want to include for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features based on importance\n",
    "# TODO\n",
    "top_features = \n",
    "X_selected = \n",
    "\n",
    "print(\"Selected features:\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model Development and Training\n",
    "\n",
    "### Task 4.1: Data Preparation and Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize your model\n",
    "# TODO\n",
    "model = \n",
    "\n",
    "# Define parameter grid for optimization\n",
    "param_grid = {\n",
    "# TODO\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "# TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(grid_search, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \"\"\"Train model and evaluate performance\"\"\"\n",
    "    # Fit model\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = best_model.predict(X_train_scaled)\n",
    "    y_pred_test = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'r2': r2_score(y_train, y_pred_train),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'mae': mean_absolute_error(y_train, y_pred_train)\n",
    "        },\n",
    "        'test': {\n",
    "            'r2': r2_score(y_test, y_pred_test),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'mae': mean_absolute_error(y_test, y_pred_test)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nModel Performance:\")\n",
    "    for dataset in ['train', 'test']:\n",
    "        print(f\"\\n{dataset.capitalize()} Set:\")\n",
    "        print(f\"R² Score: {metrics[dataset]['r2']:.4f}\")\n",
    "        print(f\"RMSE: {metrics[dataset]['rmse']:.4f}\")\n",
    "        print(f\"MAE: {metrics[dataset]['mae']:.4f}\")\n",
    "    \n",
    "    return best_model, metrics, y_pred_train, y_pred_test\n",
    "\n",
    "# Train and evaluate model\n",
    "best_model, metrics, y_pred_train, y_pred_test = train_and_evaluate_model(\n",
    "    grid_search, X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3: Model Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_analysis(y_true, y_pred, title):\n",
    "    \"\"\"Create detailed prediction analysis plots\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    ax1.scatter(y_true, y_pred, alpha=0.5)\n",
    "    ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "    ax1.set_xlabel('Actual Values')\n",
    "    ax1.set_ylabel('Predicted Values')\n",
    "    ax1.set_title(f'{title} - Actual vs Predicted')\n",
    "    \n",
    "    # Residuals\n",
    "    residuals = y_pred - y_true\n",
    "    ax2.scatter(y_pred, residuals, alpha=0.5)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--')\n",
    "    ax2.set_xlabel('Predicted Values')\n",
    "    ax2.set_ylabel('Residuals')\n",
    "    ax2.set_title(f'{title} - Residual Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training set results\n",
    "plot_prediction_analysis(y_train, y_pred_train, 'Training Set')\n",
    "\n",
    "# Plot test set results\n",
    "plot_prediction_analysis(y_test, y_pred_test, 'Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Process Parameter Optimization (Bonus)\n",
    "\n",
    "Using the model you developed, figure out what parameters should the reasearches try next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation and Final Comments\n",
    "\n",
    "TODO: Edit this cell to add your comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
